# Minimal single‑GPU run.  Adjust batch sizes / n_actors for bigger setups.

actor_rollout_ref:
  rollout:
    name: "sglang"
    multi_turn: true
    tool_kwargs:
      tools_config_file: "tools/kernel_tool.yaml"
    context_postprocessor:
      _target_: verl.utils.context_reducer.retain_last_n
      n: 6                       # keep last 6 exchanges (≈ Kevin’s recipe)
    val_kwargs:
      max_new_tokens: 2048       # long enough for kernel code + chat
    engine_kwargs:
      vllm:
        enforce_eager: true      # disable speculative streaming on ref model
  model:
    path: "Qwen/Qwen3-4B"

# parallelism – start with 4 actors if GPU‑bound; scale up as needed
n_actors: 4

algorithm:
  name: ppo
  gamma: 0.4                  # or 1.0 if gamma baked inside reward
  adv_estimator: grpo
  clip_range: 0.2
  vf_coef: 1.0
  learning_rate: 1e-5
  rollout_batch_size: 8        # per‑actor traj per update

custom_reward_function:
  path: "kevin_reward.py"
  name: "compute_score"
